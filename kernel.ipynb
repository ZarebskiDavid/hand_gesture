{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5df13e3de169bef90961ee486706c1f6cba49640"
   },
   "source": [
    "A useful thing to do with high dimensional data is to represent it first in a subspace that is convenient for a human. It will allow one to build its intuition of the dataset based on 2D or 3D representation of this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "4b2b2156e2f3c72339aaec87292ec1389208faab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['near-infrared', 'skeletal']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas\n",
    "\n",
    "INPUT_DIRECTORY = os.path.join(\"..\", \"input\")\n",
    "ARCHIVE_BASENAME = \"multimodhandgestrec\"\n",
    "ARCHIVE_SUBDIRECTORY = \"MultiModHandGestRec\"\n",
    "DATASET_DIRECTORY = os.path.join(INPUT_DIRECTORY, ARCHIVE_BASENAME, ARCHIVE_SUBDIRECTORY)\n",
    "\n",
    "os.listdir(DATASET_DIRECTORY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4b32d9a923ec63df87ec6fe20750aa529119648f"
   },
   "source": [
    "The dataset is constituted by:\n",
    "* **near-infrared** images of hand poses and gestures captured by the LeapMotion sensor (a pair of camera)\n",
    "* **skeletal** higher level informations (skeletal) about fingers and hands extracted by LeapMotion vision algorithms\n",
    "\n",
    "Near infrared images constitutes a high dimensional dataset and require sharp and state of the art computer vision algorithms in order to extract high level information about hand pose and gesture. LeapMotion did a great job on it and for the sake of simplicity, we propose to focus on skeletal data first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import cv2\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "FRAME_MATCHER = re.compile(\"fram[a|e]_(\\d+)\")\n",
    "# define constants related to dataset structure\n",
    "DEPTH = len(DATASET_DIRECTORY.split(os.sep)) + 1 # path to DATASET_DIRECTORY depth + 1 for modality \n",
    "PATH = \"path\"\n",
    "\n",
    "def extract_fields(path):\n",
    "    assert(path)\n",
    "    fields = path.split(os.sep)\n",
    "\n",
    "    subject = fields[DEPTH + 0]\n",
    "    serie = fields[DEPTH + 1]\n",
    "    gesture = fields[DEPTH + 2]\n",
    "    \n",
    "    field = fields[DEPTH + 3]\n",
    "    if (field.isnumeric()):\n",
    "        trial = field\n",
    "    else:\n",
    "        trial = \"00\"  \n",
    "\n",
    "    filename, file_extension = os.path.splitext(os.path.basename(path))\n",
    "    result = FRAME_MATCHER.match(filename)\n",
    "    if (not result):\n",
    "        raise RuntimeError(\"Unexpected filename \" + filename)\n",
    "    frame = result.group(1)\n",
    "            \n",
    "    return subject, serie, gesture, trial, frame\n",
    "\n",
    "def extract_near_infrared(path):\n",
    "    subject, serie, gesture, trial, frame = extract_fields(path)\n",
    "    \n",
    "#    color = cv2.imread(path)\n",
    "#    gray = cv2.cvtColor(color, cv2.COLOR_BGR2GRAY)\n",
    "#    normalized = cv2.normalize(gray.astype('float'), None, 0.0, 1.0, cv2.NORM_MINMAX)\n",
    "    normalized = \"0\"\n",
    "    \n",
    "    return subject, serie, gesture, trial, frame, normalized\n",
    "\n",
    "def extract_skeleton(path):\n",
    "    subject, serie, gesture, trial, frame = extract_fields(path)\n",
    "    \n",
    "    file_storage = cv2.FileStorage(path, cv2.FILE_STORAGE_READ)\n",
    "    \n",
    "    set_trace()\n",
    " \n",
    "    #features = read_features\n",
    "    features = \"0.0\"\n",
    "    return subject, serie, gesture, trial, frame, features\n",
    "\n",
    "EXTRACT = {\"near-infrared\": extract_near_infrared, \"skeletal\":extract_skeleton}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path         object\n",
      "subject       int64\n",
      "serie      category\n",
      "gesture    category\n",
      "trial         int64\n",
      "frame         int64\n",
      "data         object\n",
      "dtype: object\n",
      "                                                 path  subject         serie  \\\n",
      "0   ..\\input\\multimodhandgestrec\\MultiModHandGestR...        0  test_gesture   \n",
      "1   ..\\input\\multimodhandgestrec\\MultiModHandGestR...        0  test_gesture   \n",
      "2   ..\\input\\multimodhandgestrec\\MultiModHandGestR...        0  test_gesture   \n",
      "3   ..\\input\\multimodhandgestrec\\MultiModHandGestR...        0  test_gesture   \n",
      "4   ..\\input\\multimodhandgestrec\\MultiModHandGestR...        0  test_gesture   \n",
      "5   ..\\input\\multimodhandgestrec\\MultiModHandGestR...        0  test_gesture   \n",
      "6   ..\\input\\multimodhandgestrec\\MultiModHandGestR...        0  test_gesture   \n",
      "7   ..\\input\\multimodhandgestrec\\MultiModHandGestR...        0  test_gesture   \n",
      "8   ..\\input\\multimodhandgestrec\\MultiModHandGestR...        0  test_gesture   \n",
      "9   ..\\input\\multimodhandgestrec\\MultiModHandGestR...        0  test_gesture   \n",
      "10  ..\\input\\multimodhandgestrec\\MultiModHandGestR...        0  test_gesture   \n",
      "11  ..\\input\\multimodhandgestrec\\MultiModHandGestR...        0  test_gesture   \n",
      "12  ..\\input\\multimodhandgestrec\\MultiModHandGestR...        0  test_gesture   \n",
      "13  ..\\input\\multimodhandgestrec\\MultiModHandGestR...        0  test_gesture   \n",
      "14  ..\\input\\multimodhandgestrec\\MultiModHandGestR...        0  test_gesture   \n",
      "15  ..\\input\\multimodhandgestrec\\MultiModHandGestR...        0  test_gesture   \n",
      "16  ..\\input\\multimodhandgestrec\\MultiModHandGestR...        0  test_gesture   \n",
      "17  ..\\input\\multimodhandgestrec\\MultiModHandGestR...        0  test_gesture   \n",
      "18  ..\\input\\multimodhandgestrec\\MultiModHandGestR...        0  test_gesture   \n",
      "19  ..\\input\\multimodhandgestrec\\MultiModHandGestR...        0  test_gesture   \n",
      "20  ..\\input\\multimodhandgestrec\\MultiModHandGestR...        0  test_gesture   \n",
      "21  ..\\input\\multimodhandgestrec\\MultiModHandGestR...        0  test_gesture   \n",
      "22  ..\\input\\multimodhandgestrec\\MultiModHandGestR...        0  test_gesture   \n",
      "23  ..\\input\\multimodhandgestrec\\MultiModHandGestR...        0  test_gesture   \n",
      "24  ..\\input\\multimodhandgestrec\\MultiModHandGestR...        0  test_gesture   \n",
      "25  ..\\input\\multimodhandgestrec\\MultiModHandGestR...        0  test_gesture   \n",
      "26  ..\\input\\multimodhandgestrec\\MultiModHandGestR...        0  test_gesture   \n",
      "27  ..\\input\\multimodhandgestrec\\MultiModHandGestR...        0  test_gesture   \n",
      "28  ..\\input\\multimodhandgestrec\\MultiModHandGestR...        0  test_gesture   \n",
      "29  ..\\input\\multimodhandgestrec\\MultiModHandGestR...        0  test_gesture   \n",
      "..                                                ...      ...           ...   \n",
      "70  ..\\input\\multimodhandgestrec\\MultiModHandGestR...        0  test_gesture   \n",
      "71  ..\\input\\multimodhandgestrec\\MultiModHandGestR...        0  test_gesture   \n",
      "72  ..\\input\\multimodhandgestrec\\MultiModHandGestR...        0  test_gesture   \n",
      "73  ..\\input\\multimodhandgestrec\\MultiModHandGestR...        0  test_gesture   \n",
      "74  ..\\input\\multimodhandgestrec\\MultiModHandGestR...        0  test_gesture   \n",
      "75  ..\\input\\multimodhandgestrec\\MultiModHandGestR...        0  test_gesture   \n",
      "76  ..\\input\\multimodhandgestrec\\MultiModHandGestR...        0  test_gesture   \n",
      "77  ..\\input\\multimodhandgestrec\\MultiModHandGestR...        0  test_gesture   \n",
      "78  ..\\input\\multimodhandgestrec\\MultiModHandGestR...        0  test_gesture   \n",
      "79  ..\\input\\multimodhandgestrec\\MultiModHandGestR...        0  test_gesture   \n",
      "80  ..\\input\\multimodhandgestrec\\MultiModHandGestR...        0  test_gesture   \n",
      "81  ..\\input\\multimodhandgestrec\\MultiModHandGestR...        0  test_gesture   \n",
      "82  ..\\input\\multimodhandgestrec\\MultiModHandGestR...        0  test_gesture   \n",
      "83  ..\\input\\multimodhandgestrec\\MultiModHandGestR...        0  test_gesture   \n",
      "84  ..\\input\\multimodhandgestrec\\MultiModHandGestR...        0  test_gesture   \n",
      "85  ..\\input\\multimodhandgestrec\\MultiModHandGestR...        0  test_gesture   \n",
      "86  ..\\input\\multimodhandgestrec\\MultiModHandGestR...        0  test_gesture   \n",
      "87  ..\\input\\multimodhandgestrec\\MultiModHandGestR...        0  test_gesture   \n",
      "88  ..\\input\\multimodhandgestrec\\MultiModHandGestR...        0  test_gesture   \n",
      "89  ..\\input\\multimodhandgestrec\\MultiModHandGestR...        0  test_gesture   \n",
      "90  ..\\input\\multimodhandgestrec\\MultiModHandGestR...        0  test_gesture   \n",
      "91  ..\\input\\multimodhandgestrec\\MultiModHandGestR...        0  test_gesture   \n",
      "92  ..\\input\\multimodhandgestrec\\MultiModHandGestR...        0  test_gesture   \n",
      "93  ..\\input\\multimodhandgestrec\\MultiModHandGestR...        0  test_gesture   \n",
      "94  ..\\input\\multimodhandgestrec\\MultiModHandGestR...        0  test_gesture   \n",
      "95  ..\\input\\multimodhandgestrec\\MultiModHandGestR...        0  test_gesture   \n",
      "96  ..\\input\\multimodhandgestrec\\MultiModHandGestR...        0  test_gesture   \n",
      "97  ..\\input\\multimodhandgestrec\\MultiModHandGestR...        0  test_gesture   \n",
      "98  ..\\input\\multimodhandgestrec\\MultiModHandGestR...        0  test_gesture   \n",
      "99  ..\\input\\multimodhandgestrec\\MultiModHandGestR...        0  test_gesture   \n",
      "\n",
      "          gesture  trial  frame data  \n",
      "0            02_l      0   4312    0  \n",
      "1            02_l      0   4324    0  \n",
      "2            02_l      0   4448    0  \n",
      "3            02_l      0   4459    0  \n",
      "4            02_l      0   4583    0  \n",
      "5            02_l      0   4595    0  \n",
      "6            02_l      1   4631    0  \n",
      "7            02_l      1   4676    0  \n",
      "8            02_l      1   4686    0  \n",
      "9            02_l      1   4816    0  \n",
      "10           02_l      1   4829    0  \n",
      "11           02_l      1   4879    0  \n",
      "12           02_l      2   4922    0  \n",
      "13           02_l      2   4966    0  \n",
      "14           02_l      2   5012    0  \n",
      "15           02_l      2   5117    0  \n",
      "16           02_l      2   5272    0  \n",
      "17           02_l      2   5284    0  \n",
      "18           02_l      2   5341    0  \n",
      "19           02_l      3   5512    0  \n",
      "20           02_l      3   5774    0  \n",
      "21           02_l      3   5844    0  \n",
      "22           02_l      3   5856    0  \n",
      "23           02_l      3   5856    0  \n",
      "24           02_l      3   5868    0  \n",
      "25           02_l      3   5892    0  \n",
      "26           02_l      4   5962    0  \n",
      "27           02_l      4   6064    0  \n",
      "28           02_l      4   6064    0  \n",
      "29           02_l      4   6220    0  \n",
      "..            ...    ...    ...  ...  \n",
      "70  04_fist_moved      4   9313    0  \n",
      "71  04_fist_moved      4   9366    0  \n",
      "72  04_fist_moved      4   9377    0  \n",
      "73  04_fist_moved      5   9455    0  \n",
      "74  04_fist_moved      5   9610    0  \n",
      "75  04_fist_moved      5   9674    0  \n",
      "76  04_fist_moved      5   9795    0  \n",
      "77  04_fist_moved      5   9845    0  \n",
      "78  04_fist_moved      5   9903    0  \n",
      "79  04_fist_moved      5   9984    0  \n",
      "80       06_index      0  15156    0  \n",
      "81       06_index      0  15176    0  \n",
      "82       06_index      0  15221    0  \n",
      "83       06_index      0  15268    0  \n",
      "84       06_index      0  15297    0  \n",
      "85       06_index      0  15400    0  \n",
      "86       06_index      1  15421    0  \n",
      "87       06_index      1  15593    0  \n",
      "88       06_index      1  15604    0  \n",
      "89       06_index      1  15692    0  \n",
      "90       06_index      1  15797    0  \n",
      "91       06_index      1  15885    0  \n",
      "92       06_index      2  15953    0  \n",
      "93       06_index      2  16032    0  \n",
      "94       06_index      2  16169    0  \n",
      "95       06_index      2  16189    0  \n",
      "96       06_index      2  16344    0  \n",
      "97       06_index      2  16370    0  \n",
      "98       06_index      2  16432    0  \n",
      "99       06_index      3  16534    0  \n",
      "\n",
      "[100 rows x 7 columns]\n",
      "> \u001b[1;32m<ipython-input-5-c4b0d5e3a5cb>\u001b[0m(50)\u001b[0;36mextract_skeleton\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m     48 \u001b[1;33m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     49 \u001b[1;33m    \u001b[1;31m#features = read_features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m---> 50 \u001b[1;33m    \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"0.0\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     51 \u001b[1;33m    \u001b[1;32mreturn\u001b[0m \u001b[0msubject\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mserie\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgesture\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     52 \u001b[1;33m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> print(file_storage.getNode(\"Frame\").getNode(\"ID\").float())\n",
      "*** AttributeError: 'cv2.FileNode' object has no attribute 'float'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipdb> print(file_storage.getNode(\"Frame\").getNode(\"ID\").real())\n",
      "4312.0\n",
      "ipdb> print(file_storage.getNode(\"Frame\").getNode(\"ID\").integer())\n",
      "*** AttributeError: 'cv2.FileNode' object has no attribute 'integer'\n",
      "ipdb> print(file_storage.getNode(\"Frame\").getNode(\"ID\").int())\n",
      "*** AttributeError: 'cv2.FileNode' object has no attribute 'int'\n",
      "ipdb> print(file_storage.getNode(\"Frame\").getNode(\"ID\").string())\n",
      "\n",
      "ipdb> print(file_storage.getNode(\"Frame\").getNode(\"ID\").mat())\n",
      "*** cv2.error: OpenCV(3.4.1) C:\\Miniconda3\\conda-bld\\opencv-suite_1533128839831\\work\\modules\\core\\src\\persistence_c.cpp:1422: error: (-2) The node does not represent a user object (unknown type?) in function cvRead\n",
      "ipdb> print(file_storage.getNode(\"Frame\").getNode(\"ID\").real())\n",
      "4312.0\n",
      "ipdb> print(file_storage.getNode(\"Frame\").getNode(\"ID\").float())\n",
      "*** AttributeError: 'cv2.FileNode' object has no attribute 'float'\n",
      "ipdb> print(file_storage.getNode(\"Frame\").getNode(\"ID\"))\n",
      "<FileNode 00000221FCAE4D90>\n",
      "ipdb> print(file_storage.getNode(\"Frame\").getNode(\"ID\").real())\n",
      "4312.0\n"
     ]
    }
   ],
   "source": [
    "# initialize dataset as an empty hash table\n",
    "dataset={}\n",
    "\n",
    "# iterate trough modalities and build dataset\n",
    "for modality in os.listdir(DATASET_DIRECTORY):\n",
    "    \n",
    "    # create a tabular data structure according to the directory structure and store it in a ahsh table indexed by modality\n",
    "    subdirectory = os.path.join(DATASET_DIRECTORY, modality)\n",
    "    paths = [os.path.join(path, filename) for path, filename, files in os.walk(subdirectory) for filename in files]\n",
    "    data = pandas.DataFrame({PATH: paths})\n",
    "    \n",
    "    # initialize different levels of the path structure of the stored dataset as attributes of the dataset table\n",
    "    data[\"subject\"],\\\n",
    "    data[\"serie\"],\\\n",
    "    data[\"gesture\"],\\\n",
    "    data[\"trial\"],\\\n",
    "    data[\"frame\"],\\\n",
    "    data[\"data\"] = zip(*data[\"path\"].map(EXTRACT[modality]))\n",
    "    \n",
    "    # batch cast the Series datatype (faster than casting in extract_field)\n",
    "    data[\"subject\"] = data[\"subject\"].astype(\"int64\")\n",
    "    data[\"serie\"] = data[\"serie\"].astype(\"category\")\n",
    "    data[\"gesture\"] = data[\"gesture\"].astype(\"category\")\n",
    "    data[\"trial\"] = data[\"trial\"].astype(\"int64\")\n",
    "    data[\"frame\"] = data[\"frame\"].astype(\"int64\")\n",
    "  #  data[\"data\"] = data[\"data\"].astype(\"float32\")\n",
    "\n",
    "    # extract numerical data from files \n",
    "    print(data.dtypes)\n",
    "    print(data.head(100))\n",
    "    \n",
    "    dataset[modality] = data; "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "940977495878241bc42b2491418efb012a43be8f"
   },
   "source": [
    "**Principal component analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b869abedd17ee749e822cacb3680a59f6d6f34f8"
   },
   "source": [
    "**Self organizing map**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
